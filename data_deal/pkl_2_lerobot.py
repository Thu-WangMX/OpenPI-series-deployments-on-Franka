"""
LeRobot æ‰¹é‡æ•°æ®è½¬æ¢è„šæœ¬ (v3: é€‚é… 10ç»´ Rot6D State/Action + Effort + Wrench)
å¯¹åº”æ•°æ®é›†: /work/wmx/dataset_1217/data_used
"""
import pickle
import numpy as np
import torch
from pathlib import Path
from tqdm import tqdm
import shutil
import sys

# å°è¯•å¯¼å…¥ LeRobotDataset
try:
    from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
except ImportError:
    from lerobot.datasets.lerobot_dataset import LeRobotDataset

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
# 1. è¾“å…¥è·¯å¾„ (ä½ åˆšåˆšæ‰¹é‡å¤„ç†åçš„æ–‡ä»¶å¤¹)
RAW_DATA_DIR = Path("/work/wmx/dataset_1227_205")

# 2. è¾“å‡º Repo ID
REPO_ID = "wmx/openpi_red_1227_205_clean"

# 3. å…¶ä»–å‚æ•°
MIN_FRAMES = 15  
FPS = 30
ROBOT_TYPE = "FR3"  # æˆ– "Panda"
# ===============================================

def load_pkl(file_path):
    with open(file_path, "rb") as f:
        return pickle.load(f)

def main():
    # --- 0. å¼ºåˆ¶æ¸…ç†æ—§çš„ HuggingFace ç¼“å­˜ ---
    cache_dir = Path.home() / ".cache/huggingface/lerobot" / REPO_ID
    if cache_dir.exists():
        print(f"ğŸ§¹ æ¸…ç†æ—§ç¼“å­˜ç›®å½•: {cache_dir}")
        shutil.rmtree(cache_dir)
    
    # æ‰«æ pkl æ–‡ä»¶
    # å‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º episode_0.pkl, episode_1.pkl ... æŒ‰æ•°å­—æ’åº
    pkl_files = sorted(list(RAW_DATA_DIR.glob("*.pkl")), key=lambda x: int(x.stem.split('_')[-1]) if '_' in x.stem else 0)
    
    if not pkl_files:
        print(f"âŒ é”™è¯¯: åœ¨ {RAW_DATA_DIR} æœªæ‰¾åˆ° .pkl æ–‡ä»¶")
        return
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(pkl_files)} ä¸ª episodes.")

    # --- 1. æ¢æµ‹ç‰¹å¾ (Probe Features) ---
    print("ğŸ” æ­£åœ¨æ¢æµ‹æ•°æ®ç‰¹å¾ç»´åº¦...")
    try:
        sample_data = load_pkl(pkl_files[0])
        first_frame = sample_data[0]
        obs_sample = first_frame['observations']

        # [æ¢æµ‹] å›¾åƒå°ºå¯¸
        img1 = np.array(obs_sample['pixels']['image'])
        img2 = np.array(obs_sample['pixels']['image2'])
        h1, w1, c1 = img1.shape
        h2, w2, c2 = img2.shape
        
        # [æ¢æµ‹] Action ç»´åº¦ (åº”è¯¥æ˜¯ 10: Pos3 + Rot6D + Grip1)
        act_dim = first_frame['action'].shape[0]
        
        # [æ¢æµ‹] State ç»´åº¦ (åº”è¯¥æ˜¯ 10)
        state_dim = obs_sample['state'].shape[0]
        
        # [æ¢æµ‹] Wrench ç»´åº¦ (åº”è¯¥æ˜¯ 6)
        wrench_dim = obs_sample['tcp_wrench'].shape[0]
            
        # [æ¢æµ‹] Effort ç»´åº¦ (åº”è¯¥æ˜¯ 7, å¯¹åº”ä¹‹å‰çš„ tau_J)
        effort_dim = obs_sample['effort'].shape[0]

        print("="*40)
        print(f"âœ… ç‰¹å¾æ¢æµ‹ç»“æœ:")
        print(f"   - Action Dim: {act_dim} (æœŸæœ› 10)")
        print(f"   - State  Dim: {state_dim} (æœŸæœ› 10)")
        print(f"   - Wrench Dim: {wrench_dim} (æœŸæœ› 6)")
        print(f"   - Effort Dim: {effort_dim} (æœŸæœ› 7)")
        print(f"   - Image Sizes: ({h1},{w1}) & ({h2},{w2})")
        print("="*40)
        
    except KeyError as e:
        print(f"âŒ æ¢æµ‹å¤±è´¥ï¼Œä½ çš„æ•°æ®å¯èƒ½ç¼ºå°‘é”®å€¼: {e}")
        print("è¯·ç¡®ä¿ä½ è¿è¡Œäº†ä¹‹å‰çš„ batch_process_data.py è„šæœ¬ï¼")
        return

    # --- 2. å®šä¹‰ Feature Schema ---
    features = {
        # åŠ¨ä½œ (Next State)
        "action": {
            "dtype": "float32",
            "shape": (act_dim,),
            "names": ["action"] * act_dim,
        },
        # çŠ¶æ€ (Current State: Pos + Rot6D + Gripper)
        "observation.state": {
            "dtype": "float32",
            "shape": (state_dim,),
            "names": ["state"] * state_dim,
        },
        # åŠ›/åŠ›çŸ© (Force + Torque)
        "observation.tcp_wrench": {
            "dtype": "float32",
            "shape": (wrench_dim,),
            "names": ["force_x", "force_y", "force_z", "torque_x", "torque_y", "torque_z"],
        },
        # å…³èŠ‚åŠ›çŸ© (Effort / Tau_J)
        "observation.effort": {
            "dtype": "float32",
            "shape": (effort_dim,),
            "names": [f"joint_{i}" for i in range(effort_dim)],
        },
        # å›¾åƒ
        "observation.images.image": {
            "dtype": "image",
            "shape": (h1, w1, c1),
            "names": ["height", "width", "channel"],
        },
        "observation.images.image2": {
            "dtype": "image",
            "shape": (h2, w2, c2),
            "names": ["height", "width", "channel"],
        },
    }

    # --- 3. åˆ›å»ºæ•°æ®é›† ---
    print(f"ğŸ“¦ åˆå§‹åŒ– LeRobot æ•°æ®é›†: {REPO_ID}")
    dataset = LeRobotDataset.create(
        repo_id=REPO_ID,
        fps=FPS,
        robot_type=ROBOT_TYPE,
        features=features,
    )

    # --- 4. è½¬æ¢å¾ªç¯ ---
    count_success = 0

    for pkl_path in tqdm(pkl_files, desc="Converting"):
        try:
            episode_data = load_pkl(pkl_path)
            
            if len(episode_data) < MIN_FRAMES:
                continue

            # è·å–ä»»åŠ¡æè¿°
            task_desc = episode_data[0].get('language_instruction', '')
            if not task_desc:
                task_desc = episode_data[0].get('observations', {}).get('task_description', 'pick red chili pepper')

            for frame in episode_data:
                obs = frame['observations']
                
                # --- A. æå–å¹¶è½¬ä¸º Tensor ---
                # æ³¨æ„ï¼šastype(np.float32) å¾ˆé‡è¦ï¼Œå¦åˆ™ LeRobot å¯èƒ½ä¼šæŠ¥é”™
                
                # 1. Action (10ç»´)
                action_tensor = torch.from_numpy(frame['action'].astype(np.float32))
                
                # 2. State (10ç»´)
                state_tensor = torch.from_numpy(obs['state'].astype(np.float32))

                # 3. Wrench (6ç»´)
                wrench_tensor = torch.from_numpy(obs['tcp_wrench'].astype(np.float32))

                # 4. Effort (7ç»´)
                effort_tensor = torch.from_numpy(obs['effort'].astype(np.float32))

                # 5. Images
                img1_tensor = torch.from_numpy(np.array(obs['pixels']['image']))
                img2_tensor = torch.from_numpy(np.array(obs['pixels']['image2']))

                # --- B. æ·»åŠ å¸§ ---
                dataset.add_frame({
                    "action": action_tensor,
                    "observation.state": state_tensor,
                    "observation.tcp_wrench": wrench_tensor,
                    "observation.effort": effort_tensor,
                    "observation.images.image": img1_tensor,
                    "observation.images.image2": img2_tensor,
                    "task": task_desc 
                })

            # ä¿å­˜ Episode
            dataset.save_episode()
            count_success += 1

        except Exception as e:
            print(f"\nâŒ [é”™è¯¯] å¤„ç† {pkl_path.name} å¤±è´¥: {e}")
            # æ¸…ç†å½“å‰ buffer é˜²æ­¢æ±¡æŸ“ä¸‹ä¸€ä¸ª episode
            if hasattr(dataset, 'clear_episode_buffer'):
                dataset.clear_episode_buffer()
            else:
                # å…¼å®¹æ—§ç‰ˆæœ¬ LeRobot
                dataset.episode_buffer = dataset.create_episode_buffer()
            continue

    # --- 5. ç»“æŸ ---
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜å¹¶æœ€ç»ˆåŒ–æ•°æ®é›†...")
    if hasattr(dataset, 'finalize'):
        dataset.finalize()
    elif hasattr(dataset, 'consolidate'):
        dataset.consolidate()
    
    print("="*50)
    print(f"ğŸ‰ è½¬æ¢å®Œæˆï¼")
    print(f"âœ… æˆåŠŸè½¬æ¢: {count_success} / {len(pkl_files)}")
    print(f"ğŸ“‚ æ•°æ®é›†å·²ä¿å­˜è‡³ HuggingFace Cache æˆ– æœ¬åœ°è·¯å¾„")
    print("="*50)

if __name__ == "__main__":
    main()