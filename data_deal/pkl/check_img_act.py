import torch
import numpy as np
import cv2
from pathlib import Path
from tqdm import tqdm
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset

# ================= é…ç½®åŒºåŸŸ =================
REPO_ID = "wmx/openpi_merged_single_grasp"  # ä½ çš„æ•°æ®é›†ID
NUM_EPISODES = 50          # è¦åˆå¹¶çš„ Episode æ•°é‡
OUTPUT_FILENAME = "combined_50_episodes.mp4"
FPS = 30.0                 # è§†é¢‘å¸§ç‡ (å»ºè®®è®¾é«˜ä¸€ç‚¹ï¼Œæ¯”å¦‚ 30 æˆ– 60ï¼Œå¦åˆ™ 50 ä¸ª episode ä¼šçœ‹å¾ˆä¹…)
# ===========================================

def get_image_key(item):
    """è‡ªåŠ¨å¯»æ‰¾ä¸»ç›¸æœºè§†è§’çš„ Key"""
    for k in item.keys():
        if "image" in k and "wrist" not in k:
            return k
    return "observation.images.image"

def main():
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®é›†: {REPO_ID} ...")
    try:
        dataset = LeRobotDataset(repo_id=REPO_ID)
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return

    print(f"ğŸš€ å‡†å¤‡åˆå¹¶å‰ {NUM_EPISODES} ä¸ª Episode...")
    
    # 1. åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨ (åªéœ€ä¸€æ¬¡)
    # å…ˆè¯»å–ç¬¬0å¸§æ¥è·å–å›¾åƒå°ºå¯¸
    first_item = dataset[0]
    img_key = get_image_key(first_item)
    sample_img = first_item[img_key]
    H, W = sample_img.shape[1], sample_img.shape[2]
    
    print(f"ğŸ“º è§†é¢‘åˆ†è¾¨ç‡: {W}x{H}, å¸§ç‡: {FPS}")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(OUTPUT_FILENAME, fourcc, FPS, (W, H))

    # ç»Ÿè®¡æ€»å¸§æ•°ç”¨äºè¿›åº¦æ¡
    total_frames = 0
    for i in range(min(NUM_EPISODES, dataset.num_episodes)):
        total_frames += (dataset.episode_data_index["to"][i] - dataset.episode_data_index["from"][i]).item()

    print(f"ğŸï¸ é¢„è®¡æ€»å¸§æ•°: {total_frames}")

    # 2. éå† Episode å¹¶å†™å…¥åŒä¸€ä¸ªè§†é¢‘æ–‡ä»¶
    pbar = tqdm(total=total_frames, unit="frame")
    
    for ep_idx in range(min(NUM_EPISODES, dataset.num_episodes)):
        # è·å–å½“å‰ Episode çš„èµ·æ­¢å¸§
        from_idx = dataset.episode_data_index["from"][ep_idx].item()
        to_idx = dataset.episode_data_index["to"][ep_idx].item()
        
        # éå†å½“å‰ Episode çš„æ¯ä¸€å¸§
        for i in range(from_idx, to_idx):
            item = dataset[i]
            
            # --- å¤„ç†å›¾åƒ ---
            img_tensor = item[img_key]
            img_np = img_tensor.permute(1, 2, 0).numpy()
            if img_np.max() <= 1.05:
                img_np = (img_np * 255).astype(np.uint8)
            else:
                img_np = img_np.astype(np.uint8)
            
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

            # --- å¤„ç†åŠ¨ä½œä¸å åŠ æ–‡å­— ---
            action = item.get('action', item.get('actions'))
            if action is not None:
                act_np = action.float().numpy() if isinstance(action, torch.Tensor) else action
                z_val = act_np[2] # Zè½´
                
                # é¢œè‰²ï¼šè´Ÿæ•°(çº¢), æ­£æ•°(ç»¿)
                color = (0, 0, 255) if z_val < 0 else (0, 255, 0)
                
                # åœ¨ç”»é¢ä¸Šå åŠ ä¿¡æ¯
                # ç¬¬ä¸€è¡Œï¼šZè½´æ•°å€¼
                cv2.putText(img_bgr, f"Z: {z_val:.4f}", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
                # ç¬¬äºŒè¡Œï¼šå½“å‰ Episode å’Œ å¸§å·
                cv2.putText(img_bgr, f"Ep: {ep_idx} | Frame: {i}", (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)

            # å†™å…¥è§†é¢‘
            out.write(img_bgr)
            pbar.update(1)
        
        # (å¯é€‰) åœ¨ Episode ä¹‹é—´æ’å…¥å‡ å¸§é»‘å±æˆ–è¿‡æ¸¡ï¼Œæ–¹ä¾¿åŒºåˆ†ï¼Ÿ
        # è¿™é‡Œä¸ºäº†ä¿æŒè¿è´¯æ€§ï¼Œæš‚ä¸æ’å…¥ï¼Œä½ å¯ä»¥çœ‹å·¦ä¸Šè§’çš„ Ep ç¼–å·å˜åŒ–ã€‚

    pbar.close()
    out.release()

    print("\n" + "="*50)
    print(f"âœ… åˆå¹¶è§†é¢‘å·²ç”Ÿæˆ: {OUTPUT_FILENAME}")
    print("è¯·ä¸‹è½½å¹¶æ’­æ”¾ã€‚ä½ å¯ä»¥é€šè¿‡æ‹–åŠ¨è¿›åº¦æ¡å¿«é€Ÿæµè§ˆè¿™ 50 ä¸ª Episodeã€‚")
    print("é‡ç‚¹æ£€æŸ¥ï¼šæ˜¯å¦æ¯ä¸ª Episode çš„æŠ“å–åŠ¨ä½œå‘ç”Ÿæ—¶ï¼ŒZ å€¼éƒ½æ˜¯è´Ÿæ•°ï¼Ÿ")

if __name__ == "__main__":
    main()